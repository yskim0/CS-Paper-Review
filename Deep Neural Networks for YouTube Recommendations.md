# Deep Neural Networks for YouTube Recommendations

## Overview

Discovering personalized content by Recommendation System

> [ Problem ]
1. Scale: massive user base and corpus (media quantity)  highly specialized distributed learning algorithms and efficient serving systems
2. Freshness: dynamic corpus uploaded per second  responsive enough to model newly uploaded content as well as the latest actions taken by the user, balancing new content with well-established videos
3. Noise: sparse and a variety of unobservable external factors, poorly structured metadata associated with content  robust to these sparse and difficult characteristics

> [ Solution ]
1. Candidate Generation Model: Collaborative Filtering(=Deep Neural Network), benefiting from deep layers of hidden units and additional heterogeneous signals
2. Ranking Model: modifying classic logistic regression to train a model predicting expected watch time

> [ System Overview ]

two neural networks : Candidate Generation + Ranking
* live experiments: measure user engagement (subtle changes in click-through rate, watch time)
1. Candidate Generation Model: takes events from the user’s YouTube activity history as input and retrieves a small subset of videos from a large corpus
- relevant to the user with high precision, broad personalization
- similarity between users: coarse features // IDs of video watches, search query tokens, demographics  requires a fine-level presentation to distinguish relative importance among candidates with high recall
2. Ranking Network: assigning a score to each video features describing the video and user  highest scoring videos are presented to the user
 recommending the small number of videos personalized and engaging for the user, blending candidates generated by other sources (videos from external sources)

## Related Work

Deep Neural Networks for Recommendation Systems
- recommending news, citations, review ratings
Collaborative Filtering
- Deep neural network
- Auto-encoders
Deep Learning
- Cross domain user modeling

## Methods

1. Candidate Generation Model: winnowing down to hundreds of videos that may be relevant to the user
- predecessor to the recommender: matrix factorization approach trained under rank loss
 = early iterations mimicked matrix factorization with shallow networks that only embedded the user’s previous watches  non-linear generalization of factorization techniques


 1) Recommendation as Classification: Classification = extreme multiclass classification
- prediction problem = accurately classifying a specific video wt, watch at time t, among millions of videos i (classes), from a corpus V, based on a user U and context C

( u = high-dimensional embedding of the user, context pair / v = embeddings of each candidate video )
 Deep Neural Network: learn user embeddings u as a function of the user’s history and context that are useful for discriminating among videos with a softmax classifier
- Efficient Extreme Multiclass:
1> Candidate Sampling: sampling negative classes from the background distribution
2> correcting via importance weighting (cross-entropy loss is minimized for the true label and the sampled negative classes) – 100 times faster than original softmax classifier
3> Hashing: computing most likely N classes (videos) – presented videos to users
 - scoring scheme sublinear in the number of classes that scores millions of items under a strict serving latency of tens of milliseconds
 - nearest neighbor search in the dot product space

2) Model Architecture
  learn high dimensional embeddings for each video in a fixed vocabulary  feed these embeddings into a feedforward neural network  user’s watch history is represented by a variable-length sequence of sparse video IDs which is mapped to a dense vector representation via the embeddings  averaging the embeddings to fix input size)  learned jointly with other parameters through normal gradient descent backpropagation updates  concatenated into a side first layer, followed by several layers of fully connected ReLU

3) Heterogeneous Signals
  * Deep Neural Network as a generalization of matrix factorization: arbitrary continuous and categorical features can be added to the model
  1> Search history: each query is tokenized into unigrams and bigrams  embedded  averaged = summarized dense search history
  2> demographic features (geographic region and device): embedded  concatenated
  3> simple binary and continuous features // gender, logged-in state, age: input directly into the network as real values normalized to [0,1]
  * Machine learning systems: by training to predict future behavior from historical examples  exhibit an implicit bias towards the past
  4> “Example Age” Feature: feed the age of the training example as a feature during training = multinomial distribution over the corpus will reflect the average watch likelihood in the training window


4) Label and Context Selection
  - surrogate learning problem: training examples are generated from all YouTube watches including embedded on other sites rather than recommended videos
  1> propagate this discovery to others via collaborative filtering model
  2> generate fixed number of training examples per user, effectively weighting users equally in the loss function model
  - withhold information to prevent exploiting and overfitting the surrogate problem: discarding sequence information and representing search queries with an unordered bag of tokens, the classifier is no longer directly aware of the origin of the label

5) Experiments with Features and Depth
- adding features and depth: improves precision on holdout data


1. softmax layer  multinomial distribution over the same 1M video classes with a dimension of 256 (separate output video embedding)  trained with several epochs
2. tower pattern: bottom of the network is widest, each successive hidden layer halves the number of units
3. depth zero = linear factorization scheme = predecessor system
4. added until the incremental benefit diminished and convergence became difficult


2. Ranking Model: assign independent score to each video impression based on expected watch time using logistic regression  sorted
- use impression data to specialize and calibrate candidate predictions for the particular user interface
- ensemble different candidate sources whose scores are not directly comparable


1) Feature Representation
  1> categorical features
    # cardinality
    - binary
    - millions of possible values
    # whether they contribute
    - univalent: only a single value
    - multivalent: a set of values
    # whether they describe properties of
    - impression: the item  computed for each item scored
    - query: the user / context  computed once per request
  2> continuous / ordinal features
- Feature Engineering: transforming user and video data into useful features = representing a temporal sequence of user actions and how these actions relate to the video impression being scored
  1> describe a user’s previous interaction with the item itself and other similar items, matching others’ experience
  2> propagate information from candidate generation into ranking in the form of features
  3> features describing the frequency of past video impression: introducing churn in recommendations
  # Embedding Categorical Features: map sparse categorical features to dense representations suitable for neural networks
    - each feature is fed separately into the network  higher layers: learn specialized representations per feature
    - sharing feature: generalization  speeding up training and reducing memory requirements
  # Normalizing Continuous Features
    

2) Modeling Expected Watch Time
- logistic regression under cross-entropy loss:  (E[T]: expected watch time, P: click probability)
  1> positive (clicked): the amount of time the user spent watching the video
  2> negative (unclicked): unit weight

3) Experiments with Hidden Layers
- increasing the width and depth of hidden layers improves results <-> CPU time needed

## Additional Studies

* offline metrics: opposite conditions of live experiments’ results, related to several conditions and results of models
// precision, recall, ranking loss

* Collaborative Filtering Systems (= Deep Neural Network with candidate generation + ranking model): 

1> holding out a random item and predicting it from other items in the user’s history  leaks future information and ignores any asymmetric consumption patterns
2> rollback a user’s history by choosing a random watch and only input actions the user took before the held-out label watch  solving natural consumption patterns of videos which have asymmetric co-watch probabilities

## Reference

http://keunwoochoi.blogspot.com/2016/09/deep-neural-networks-for-youtube.html
